{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VladKarad/AI_education/blob/main/ChatBot_Text%20processing_Model_Sequence_to_Sequence_HW_Pro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhGFfIoFzgSc"
      },
      "source": [
        "# Добро пожаловать на задание уровня Pro.\n",
        "Необходимо написать чат-бота, испльзуя модель seq2seq.\n",
        "\n",
        "Ссылка на базу https://storage.googleapis.com/datasets_ai/Advanced/3_seq2seq/9kdialogs.txt\n",
        "\n",
        "База содержит примеры пар: вопрос-ответ. По аналогии с моделью преводчика (англ - рус), создайте чат-бота (вопрос - ответ)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Подключим модуль для загрузки файлов в colab\n",
        "from google.colab import files\n",
        "\n",
        "# Подключим модуль numpy для работы с массивами\n",
        "import numpy as np\n",
        "\n",
        "# Подгрузим модели кераса\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "\n",
        "# Подключим нужные слои\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input\n",
        "\n",
        "# Поключим оптимайзеры\n",
        "from tensorflow.keras.optimizers import RMSprop, Adadelta\n",
        "\n",
        "# Подключим метод ограничения последовательности заданной длиной\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Подключим токенайзер\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Подключим модуль для one hot кодировки\n",
        "from tensorflow.keras import utils\n",
        "\n",
        "# Подключим визуализацию графа модели\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Подключим модуль для работы с yaml - файлами\n",
        "import yaml"
      ],
      "metadata": {
        "id": "K_4GkJ0KGLhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузим обучающие тексты\n",
        "!wget  https://storage.googleapis.com/datasets_ai/Advanced/3_seq2seq/9kdialogs.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCZsipLwF9VI",
        "outputId": "ca24f7f9-c121-4f0c-9973-e46f3d6245e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-11 09:17:06--  https://storage.googleapis.com/datasets_ai/Advanced/3_seq2seq/9kdialogs.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.112.128, 74.125.124.128, 172.217.212.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.112.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 748135 (731K) [text/plain]\n",
            "Saving to: ‘9kdialogs.txt’\n",
            "\n",
            "\r9kdialogs.txt         0%[                    ]       0  --.-KB/s               \r9kdialogs.txt       100%[===================>] 730.60K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2022-01-11 09:17:07 (105 MB/s) - ‘9kdialogs.txt’ saved [748135/748135]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversations = [] \n",
        "with open(\"/content/9kdialogs.txt\", 'r', encoding='utf-8') as f: # Открываем файл словаря в режиме чтения\n",
        "    lines = f.read().replace(\"\\n\\n\",\"\").split('- -')                  # Читаем весь файл, режем на строки\n",
        "\n",
        "# Цикл по строкам\n",
        "for i,line in enumerate(lines):\n",
        "    #if i>50000:                                         # Нам нужно только 50000 первых строк\n",
        "    #  break                                             # Заканчиваем цикл\n",
        "    try:\n",
        "        input_text, target_text,_ = line.split(\"\\n\")    # Берем очередную строку, режем по символу табуляции\n",
        "        conversations.append([input_text, target_text]) # Заполняем список пар фраз\n",
        "    except:\n",
        "        continue                                        # если не получается - идем за следущей строкой"
      ],
      "metadata": {
        "id": "mNWZBmKATgaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(conversations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIwBoW6vXy1E",
        "outputId": "e3279053-731c-4ca4-e73a-86de4746e81a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "828"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def my_replacer(s): # Принимаем на вход строку или список\n",
        "\n",
        "    '''\n",
        "    Функция удаления пробелов из строк или списков, в зависимости от того, что подано на вход\n",
        "  \n",
        "    Args:\n",
        "        s - Строка или список\n",
        "    Returns:\n",
        "  \n",
        "        Список строк если получили список\n",
        "        Строку, если получили строку\n",
        "        \n",
        "    '''\n",
        "\n",
        "\n",
        "    if isinstance(s,str): # Если получили строку\n",
        "\n",
        "        # Убираем перед знаками препинания пробел и возвращаем\n",
        "        return s.replace(' .','.').replace(' ,',',').replace(' !','!').replace(' ?','?')\n",
        "\n",
        "    if isinstance(s,list): # Если получили список\n",
        "        ou=[]              # Заготовим пустой список\n",
        "\n",
        "        for l in s:        # Цикл по строкам из списка\n",
        "            ou.append(l.replace(' .','.').replace(' ,',',').replace(' !','!').replace(' ?','?')) # Убираем перед знаками препинания пробел и возвращаем\n",
        "\n",
        "        # Вернем список строк\n",
        "        return ou    "
      ],
      "metadata": {
        "id": "t9GDoYMdY_yU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Собираем вопросы и ответы в списки\n",
        "\n",
        "questions = [] # Переменная для списка входных фраз\n",
        "answers = []   # Переменная для списка ответных фраз\n",
        "\n",
        "# Цикл по всем парам фраз \n",
        "for con in conversations:                 \n",
        "  if len(con) > 1 :                       # Если ответная фраза содержит более одно двух предложений\n",
        "    questions.append(my_replacer(con[0])) # То первую в списке фразу отправляем в список входных фраз\n",
        "    replies = my_replacer(con[1:])        # А ответную составляем из последующих строк\n",
        "    ans = ' '.join(replies)               # Здесь соберем ответ\n",
        "    answers.append(ans)                   # Добавим в список ответов\n",
        "  else:\n",
        "    continue                              # Иначе идем на новой парой фраз\n",
        "\n",
        "# Добавим в каждую ответную фразу теги  <START> и <END>\n",
        "answers = ['<START> ' + s + ' <END>' for s in answers]\n",
        "\n",
        "# Выведем обновленные данные на экран\n",
        "print('Вопрос : {}'.format(questions[111])) # Пример входной фразы\n",
        "print('Ответ : {}'.format(answers[111]))    # Пример ответной фразы"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_673SgaKZXWz",
        "outputId": "4b24a6fc-4341-419b-e14b-10f2deebdfbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вопрос :  Ваша машина?\n",
            "Ответ : <START> - Моя... <END>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создадим токенайзер \n",
        "tokenizer = Tokenizer(filters='\"#$%&()*+-/;<=>@[\\\\]^_`{|}~\\t\\n',split=' ')  \n",
        "\n",
        "# Загружаем в токенизатор список фраз для сборки словаря частотности\n",
        "tokenizer.fit_on_texts(questions + answers)         \n",
        "\n",
        "# Список с cодержимым словаря\n",
        "vocabularyItems = list(tokenizer.word_index.items())    \n",
        "\n",
        "# Размер словаря\n",
        "vocabularySize = len(vocabularyItems)+1        \n",
        "\n",
        "# Выведем фрагмент и размер словаря\n",
        "print( 'Фрагмент словаря : {}'.format(vocabularyItems[:50]))       \n",
        "print( 'Размер словаря : {}'.format(vocabularySize))             "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONvGpGtlZhWD",
        "outputId": "416c0095-b684-4775-ad96-390dc4b3ce7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фрагмент словаря : [('start', 1), ('end', 2), ('что', 3), ('не', 4), ('ты', 5), ('а', 6), ('в', 7), ('это', 8), ('я', 9), ('вы', 10), ('что?', 11), ('да.', 12), ('где', 13), ('у', 14), ('и', 15), ('нет.', 16), ('на', 17), ('как', 18), ('кто', 19), ('с', 20), ('за', 21), ('же', 22), ('тебе', 23), ('он', 24), ('то', 25), ('нет,', 26), ('мне', 27), ('это?', 28), ('вас', 29), ('да,', 30), ('сколько', 31), ('вам', 32), ('еще', 33), ('кого?', 34), ('есть', 35), ('чего', 36), ('ну', 37), ('его', 38), ('только', 39), ('как?', 40), ('из', 41), ('меня', 42), ('она', 43), ('да', 44), ('здесь', 45), ('так', 46), ('тебя', 47), ('все', 48), ('мы', 49), ('ну,', 50)]\n",
            "Размер словаря : 2357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Разбиваем текст входных фраз на последовательности индексов\n",
        "tokenizedQuestions = tokenizer.texts_to_sequences(questions)\n",
        "\n",
        "# Уточняем длину самой длинной фразы\n",
        "maxLenQuestions = max([ len(x) for x in tokenizedQuestions])\n",
        "\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие фразы\n",
        "paddedQuestions = pad_sequences(tokenizedQuestions, maxlen=maxLenQuestions, padding='post')\n",
        "\n",
        "# Предподготавливаем данные для входа в сеть, переводим в numpy массив\n",
        "encoderForInput = np.array(paddedQuestions)        \n",
        "\n",
        "# Выведем на экран\n",
        "print('Пример входной фразы                         : {}'.format(questions[100]))         \n",
        "print('Пример кодированной входной фразу            : {}'.format(encoderForInput[100]))  \n",
        "print('Размеры закодированного массива входных фраз : {}'.format(encoderForInput.shape))  \n",
        "print('Установленная длина входных фраз             : {}'.format(maxLenQuestions))        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldIAjkLEZq9b",
        "outputId": "a6d5b81f-62ce-4492-e035-376a03a5ad3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример входной фразы                         :  Кто-то здесь есть.\n",
            "Пример кодированной входной фразу            : [ 19  25  45 140   0   0   0   0   0   0   0]\n",
            "Размеры закодированного массива входных фраз : (828, 11)\n",
            "Установленная длина входных фраз             : 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Разбиваем текст ответных фраз на последовательности индексов\n",
        "tokenizedAnswers = tokenizer.texts_to_sequences(answers) \n",
        "\n",
        "# Уточняем длину самого длинного ответа\n",
        "maxLenAnswers = max([len(x) for x in tokenizedAnswers])\n",
        "\n",
        "# Делаем последовательности одной длины, заполняя нулями более ответы\n",
        "paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers, padding='post')\n",
        "\n",
        "# Предподготавливаем данные для входа в сеть, переводим в numpy массив\n",
        "decoderForInput = np.array(paddedAnswers)               \n",
        "\n",
        "# Выведем на экран\n",
        "print('Пример оригинального ответа на вход: {}'.format(answers[100]))                         \n",
        "print('Пример кодированного ответа на вход : {}'.format(decoderForInput[100][:30]))           \n",
        "print('Размеры кодированного массива ответов на вход : {}'.format(decoderForInput.shape))     \n",
        "print('Установленная длина ответов на вход : {}'.format(maxLenAnswers))                       "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIeA_gAJZxmF",
        "outputId": "c089abd7-fb58-4db6-dcf0-9941cc17d3d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример оригинального ответа на вход: <START> - Это сквозняк, мы просто не прикрыли дверь. <END>\n",
            "Пример кодированного ответа на вход : [   1    8 1469   49  113    4 1470  444    2    0    0    0    0    0\n",
            "    0    0    0]\n",
            "Размеры кодированного массива ответов на вход : (828, 17)\n",
            "Установленная длина ответов на вход : 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Разбиваем текст ответов на последовательности индексов\n",
        "tokenizedAnswers = tokenizer.texts_to_sequences(answers) \n",
        "\n",
        "for i in range(len(tokenizedAnswers)) :                  # Для разбитых на последовательности ответов\n",
        "  tokenizedAnswers[i] = tokenizedAnswers[i][1:]          # Избавляемся от тега <START>\n",
        "\n",
        "# Делаем последовательности одной длины, заполняя нулями более короткие ответы\n",
        "paddedAnswers = pad_sequences(tokenizedAnswers, maxlen=maxLenAnswers , padding='post') \n",
        "\n",
        "# И сохраняем в виде массива numpy\n",
        "decoderForOutput = np.array(paddedAnswers)                     "
      ],
      "metadata": {
        "id": "QMrQ_5bAZ4mV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Выведем на экран\n",
        "\n",
        "print('Пример кодированного ответа на вход : {}'.format(decoderForInput[100][:21]))   \n",
        "print('Пример кодированного ответа на выход : {}'.format(decoderForOutput[100][:21]))\n",
        "print('Размеры кодированного массива ответов на выход : {}'.format(decoderForOutput.shape))  \n",
        "print('Установленная длина вопросов на выход : {}'.format(maxLenAnswers))                    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRYq48AbZ7d7",
        "outputId": "3745010d-ae4e-4a39-e552-98024505e8e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример кодированного ответа на вход : [   1    8 1469   49  113    4 1470  444    2    0    0    0    0    0\n",
            "    0    0    0]\n",
            "Пример кодированного ответа на выход : [   8 1469   49  113    4 1470  444    2    0    0    0    0    0    0\n",
            "    0    0    0]\n",
            "Размеры кодированного массива ответов на выход : (828, 17)\n",
            "Установленная длина вопросов на выход : 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создадим энкодер \n",
        "\n",
        "encoderInputs = Input(shape=(None , ))                                               # Добавим входной слой\n",
        "encoderEmbedding = Embedding(vocabularySize, 200 , mask_zero=True)(encoderInputs)    # Добавим эмбеддинг\n",
        "encoderOutputs, state_h , state_c = LSTM(200, return_state=True)(encoderEmbedding)   # Добавим LSTM\n",
        "encoderStates = [state_h, state_c]                                                   # Соберем выходы lstm  в список    \n",
        "\n",
        "# Создадим декодер \n",
        "\n",
        "decoderInputs = Input(shape=(None, ))                                                # Добавим входной слой\n",
        "decoderEmbedding = Embedding(vocabularySize, 200, mask_zero=True) (decoderInputs)    # Добавим эмбеддинг\n",
        "decoderLSTM = LSTM(200, return_state=True, return_sequences=True)                    # Создадим LSTM слой\n",
        "decoderOutputs , _ , _ = decoderLSTM (decoderEmbedding, initial_state=encoderStates) # Прогоним выход embedding через LSTM\n",
        "decoderDense = Dense(vocabularySize, activation='softmax')                           # Создадим dense слой\n",
        "output = decoderDense (decoderOutputs)                                               # Прогоним  выход LSTM через DENSE\n",
        "\n",
        "model = Model([encoderInputs, decoderInputs], output)                                # Собираем модель\n",
        "model.compile(optimizer=RMSprop(), loss='sparse_categorical_crossentropy')           # Компилиуем модель\n",
        "print(model.summary())                                                               # Выведем на экран информацию о построенной модели нейросети\n",
        "\n",
        "\n",
        "# Построим график для визуализации слоев и связей между ними\n",
        "plot_model(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 942
        },
        "id": "-Oh7AsLfZ_sr",
        "outputId": "d0f7e579-0391-4183-d358-7cc1c9dfb128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 200)    471400      ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 200)    471400      ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 200),        320800      ['embedding[0][0]']              \n",
            "                                 (None, 200),                                                     \n",
            "                                 (None, 200)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 200),  320800      ['embedding_1[0][0]',            \n",
            "                                 (None, 200),                     'lstm[0][1]',                   \n",
            "                                 (None, 200)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 2357)   473757      ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,058,157\n",
            "Trainable params: 2,058,157\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Запустим обучение\n",
        "model.fit([encoderForInput , decoderForInput], decoderForOutput, batch_size=128, epochs=100) "
      ],
      "metadata": {
        "id": "Wmg1FQbKarvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac9e8e19-a8eb-48d8-f8ca-cd5c85526ab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "7/7 [==============================] - 13s 35ms/step - loss: 2.1828\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 1.5696\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 1.4671\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 1.4242\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 1.3963\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 1.3654\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 1.3372\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 1.3090\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 1.2847\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 1.2595\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 1.2378\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 1.2171\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 1.1962\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 1.1786\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 1.1599\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 1.1428\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 1.1258\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 1.1108\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 1.0948\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 1.0789\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 1.0656\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 1.0489\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 1.0353\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 1.0190\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 1.0048\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.9901\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.9745\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.9589\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.9448\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.9285\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.9161\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.8999\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.8874\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.8727\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.8588\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.8455\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.8306\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.8166\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.8040\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.7916\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.7774\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.7655\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.7525\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.7410\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.7287\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.7155\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.7050\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6932\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.6818\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6682\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.6583\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6471\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6337\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.6231\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6152\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.6003\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5908\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5791\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5696\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5570\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5466\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5369\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5270\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5145\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5049\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.4929\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.4847\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.4739\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.4621\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.4526\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.4421\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.4342\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.4229\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.4149\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.4036\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.3937\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.3859\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.3758\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.3666\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.3568\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.3476\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.3404\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.3309\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.3203\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.3150\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.3060\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.2952\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.2889\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.2820\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.2715\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.2640\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.2576\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.2495\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.2423\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.2360\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.2283\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.2202\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.2137\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.2072\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.2021\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f71697262d0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем рабочие модели для перевода\n",
        "\n",
        "def makeInferenceModels():\n",
        "\n",
        "  '''\n",
        "  Функция для создания единой полноценной модели из энкодера и декодера\n",
        "  Собираем по отдельности энкодер и декодер для использования метода .predict() для каждого из них в конце работы для проверки результатов\n",
        "\n",
        "  Args:\n",
        "    None\n",
        "    \n",
        "  Returns:\n",
        "    Вовзращает рабочие модели энкодера и декодера для дальнейшей работы нейросети\n",
        "  '''\n",
        "\n",
        "  # Создадим модель кодера, на входе далее будут закодированные вопросы, на выходе состояния state_h, state_c\n",
        "  encoderModel = Model(encoderInputs, encoderStates) \n",
        "\n",
        "  # Создадим модель декодера\n",
        "  decoderStateInput_h = Input(shape=(200 ,)) # Добавим входной слой для state_h\n",
        "  decoderStateInput_c = Input(shape=(200 ,)) # Добавим входной слой для state_c\n",
        "\n",
        "  decoderStatesInputs = [decoderStateInput_h, decoderStateInput_c] # Соберем оба inputs вместе и запишем в decoderStatesInputs\n",
        "\n",
        "  decoderOutputs, state_h, state_c = decoderLSTM(decoderEmbedding, initial_state=decoderStatesInputs) # Берём ответы, прошедшие через эмбединг, вместе с состояниями и подаём LSTM cлою\n",
        "  decoderStates = [state_h, state_c]            # LSTM даст нам новые состояния\n",
        "  decoderOutputs = decoderDense(decoderOutputs) # И ответы, которые мы пропустим через полносвязный слой с софтмаксом\n",
        "\n",
        "  # Определим модель декодера, на входе далее будут раскодированные ответы (decoderForInputs) и состояния\n",
        "  # на выходе предсказываемый ответ и новые состояния\n",
        "  decoderModel = Model([decoderInputs] + decoderStatesInputs, [decoderOutputs] + decoderStates)\n",
        "\n",
        "  # Вернем рабочие модели энкодера и декодера  \n",
        "  return encoderModel , decoderModel"
      ],
      "metadata": {
        "id": "XuqLz9ntbb1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def strToTokens(sentence: str):     # Функция принимает входную фразу\n",
        "\n",
        "  '''\n",
        "  Функция для очистки фразы и преобразования в индексы по словарю в токенайзере\n",
        "\n",
        "  Args:\n",
        "    sentence - фраза, формата str\n",
        "\n",
        "  Returns:\n",
        "    None, если незнакомые символы фразы\n",
        "    Входная фраза в виде последовательности символов, если смогли определить индексы\n",
        "  '''\n",
        "  \n",
        "  tmp_sent = my_replacer(sentence)                                              # Почистим фразу\n",
        "  words = tmp_sent.lower().split()                                              # Приводит предложение к нижнему регистру и разбирает на слова\n",
        "  tokensList = list()                                                           # Здесь будет последовательность токенов/индексов\n",
        "\n",
        "  # Для каждого слова в предложении\n",
        "  for word in words:\n",
        "    try:\n",
        "        tokensList.append(tokenizer.word_index[word])                           # Определяем токенайзером индекс и добавляем в список\n",
        "    except:\n",
        "        pass                                                                    # Слова нет - просто игнорируем его\n",
        "\n",
        "  # Вернёт входную фразу в виде последовательности индексов\n",
        "  if tokensList:\n",
        "    return pad_sequences([tokensList], maxlen=maxLenQuestions , padding='post')\n",
        "\n",
        "  return None                                                                   # Фраза из незнакомх слов - вернем None "
      ],
      "metadata": {
        "id": "eIaqlBe2bgob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Запускаем функцию для построения модели кодера и декодера\n",
        "\n",
        "encModel , decModel = makeInferenceModels() "
      ],
      "metadata": {
        "id": "o2qXkXagbmpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Цикл по количеству входных фраз - их 1\n",
        "for _ in range(1): # задаем количество вопросов, и на каждой итерации в этом диапазоне:\n",
        "\n",
        "  # Получаем значения состояний, которые определит кодер в соответствии с заданным вопросом\n",
        "  decodedTranslation0 = input('Задай вопрос - получишь ответ от бота: ')\n",
        "  qua  = strToTokens(decodedTranslation0)\n",
        "\n",
        "  if qua is None:                                      # В запросе сплошные незнакомые слова...\n",
        "    print (\"а вот спросите меня о чем-нить полезном: \")  # Выдадим дежурную фразу\n",
        "    continue                                           # Пойдем за следущей фразой\n",
        "\n",
        "  statesValues = encModel.predict(qua)                 # Прогоним фразу через энкодер\n",
        "  \n",
        "  emptyTargetSeq = np.zeros((1, 1))                    # Создадим пустой массив\n",
        "  emptyTargetSeq[0, 0] = tokenizer.word_index['start'] # Положим в пустую последовательность начальное слово 'start' в виде индекса\n",
        "  stopCondition = False                                # Зададим условие, при срабатывании которого, прекратится генерация очередного слова\n",
        "  decodedTranslation = ''                              #Здесь будет собираться генерируемый ответ\n",
        "\n",
        "  while not stopCondition:                             # пока не сработало стоп-условие\n",
        "\n",
        "    # В модель декодера подадим пустую последовательность со словом 'start' и состояния предсказанные кодером по заданному вопросу.\n",
        "    # декодер заменит слово 'start' предсказанным сгенерированным словом и обновит состояния\n",
        "    decOutputs , h , c = decModel.predict([emptyTargetSeq] + statesValues)\n",
        "    \n",
        "    sampledWordIndex = np.argmax( decOutputs[0, 0, :]) # Получим индекс предсказанного слова.\n",
        "    sampledWord = None                                 # Создаем переменную, в которую положим слово, преобразованное на естественный язык\n",
        "\n",
        "    # Цикл по всем индексам токенайзера\n",
        "    for word , index in tokenizer.word_index.items():\n",
        "      if sampledWordIndex == index:              # Если индекс выбранного слова соответствует какому-то индексу из словаря\n",
        "        decodedTranslation += ' {}'.format(word) # Слово, идущее под этим индексом в словаре, добавляется в итоговый ответ \n",
        "        sampledWord = word                       # Выбранное слово фиксируем в переменную sampledWord\n",
        "    \n",
        "    # Если выбранным словом оказывается 'end' либо если сгенерированный ответ превышает заданную максимальную длину ответа\n",
        "    if sampledWord == 'end' or len(decodedTranslation.split()) > maxLenAnswers:\n",
        "      stopCondition = True # Срабатывает стоп-условие и прекращаем генерацию\n",
        "\n",
        "    emptyTargetSeq = np.zeros((1, 1))       # Создаем пустой массив\n",
        "    emptyTargetSeq[0, 0] = sampledWordIndex # Заносим туда индекс выбранного слова\n",
        "    statesValues = [h, c]                   # И состояния, обновленные декодером \n",
        "                                            # И продолжаем цикл с обновленными параметрами\n",
        "  \n",
        "  print(\"И бот ответил: \", decodedTranslation) # Выводим ответ сгенерированный декодером"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aIYx65xbsl7",
        "outputId": "b43bffd3-4166-4ea0-b423-95fdab297b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Задай вопрос - получишь ответ от бота: как\n",
            "И бот ответил:   ну, вроде жопа . end\n"
          ]
        }
      ]
    }
  ]
}
